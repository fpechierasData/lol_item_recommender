{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from requests import exceptions\n",
    "from riotwatcher import LolWatcher\n",
    "import sqlite3\n",
    "import requests\n",
    "from requests.exceptions import ConnectionError\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "import tarfile\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get('api_key')\n",
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_watcher = LolWatcher(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_players(region: str) -> list:\n",
    "    \"\"\"\n",
    "    Utilise l'API RiotWatcher pour récupérer les joueurs dans Challenger, Grandmaster et Master.\n",
    "    Retourne une liste de tous les IDs des invocateurs.\n",
    "\n",
    "    Args:\n",
    "        region (str): La région dans laquelle rechercher les joueurs (e.g., 'na1', 'euw1').\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste d'IDs des invocateurs des divisions Challenger, Grandmaster et Master.\n",
    "    \"\"\"\n",
    "\n",
    "    # Récupérer les joueurs challengers\n",
    "    challengers = lol_watcher.league.challenger_by_queue(region, 'RANKED_SOLO_5x5')\n",
    "\n",
    "    # Récupérer les joueurs grandmasters\n",
    "    gms = lol_watcher.league.grandmaster_by_queue(region, 'RANKED_SOLO_5x5')\n",
    "\n",
    "    # Récupérer les joueurs masters\n",
    "    masters = lol_watcher.league.masters_by_queue(region, 'RANKED_SOLO_5x5')\n",
    "\n",
    "    # Liste de tous les objets récupérés\n",
    "    all_top_players = [challengers, gms, masters]\n",
    "\n",
    "    # Liste pour stocker tous les IDs des invocateurs\n",
    "    summoner_ids = []\n",
    "\n",
    "    # Boucle à travers chaque division et concaténation de tous les IDs des invocateurs\n",
    "    for division in all_top_players:\n",
    "        for entry in division['entries']:\n",
    "            summoner_ids.append(entry['summonerId'])\n",
    "\n",
    "    return summoner_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = get_top_players('euw1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_list_to_json(my_list: list, filename: str):\n",
    "    \"\"\"\n",
    "    Sauvegarde une liste dans un fichier JSON.\n",
    "\n",
    "    Args:\n",
    "        my_list (list): La liste à sauvegarder.\n",
    "        filename (str): Le nom du fichier JSON.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(my_list, file)\n",
    "\n",
    "# Exemple d'utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_list_to_json(A, 'get_top_players.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_puuid(summoner_ids: list, region: str = 'euw1') -> dict:\n",
    "    \"\"\"\n",
    "    Prend en entrée une liste d'IDs d'invocateurs de l'API Riot et récupère les PUUIDs des utilisateurs.\n",
    "    Cela est nécessaire car d'autres requêtes nécessitent le PUUID.\n",
    "    Retourne un objet dict mappant l'ID de l'invocateur au PUUID.\n",
    "\n",
    "    Args:\n",
    "        summoner_ids (list): Liste des IDs des invocateurs.\n",
    "        region (str, optional): La région dans laquelle rechercher les joueurs (par défaut 'euw1').\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire mappant les IDs des invocateurs aux PUUIDs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionnaire pour stocker les valeurs\n",
    "    summid_to_puuid = {}\n",
    "\n",
    "    # Boucle à travers chaque ID d'invocateur et récupération du PUUID correspondant\n",
    "    for summoner in summoner_ids:\n",
    "        summid_to_puuid[summoner] = lol_watcher.summoner.by_id(region, summoner)['puuid']\n",
    "\n",
    "    return summid_to_puuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = get_puuid(A, 'euw1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_list_to_json(B, 'get_puuid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = cle = next(iter(B))\n",
    "# key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value = B[key]\n",
    "# value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_champ_mastery(summoner_ids: list, summid_to_puuid: dict, region: str = 'euw1', points: int = 100000) -> dict:\n",
    "    \"\"\"\n",
    "    Prend en entrée une liste d'IDs d'invocateurs et un dictionnaire mappant les IDs des invocateurs aux PUUIDs,\n",
    "    et récupère l'ID du champion pour chaque champion ayant plus de 'points'.\n",
    "    La valeur par défaut pour 'points' est 100 000.\n",
    "    Retourne un dictionnaire mappant les PUUIDs à une liste d'IDs de champions.\n",
    "\n",
    "    Args:\n",
    "        summoner_ids (list): Liste des IDs des invocateurs.\n",
    "        summid_to_puuid (dict): Dictionnaire mappant les IDs des invocateurs aux PUUIDs.\n",
    "        region (str, optional): La région dans laquelle rechercher les joueurs (par défaut 'euw1').\n",
    "        points (int, optional): Le nombre minimum de points de maîtrise pour inclure un champion (par défaut 100 000).\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire mappant les PUUIDs à une liste d'IDs de champions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crée un dictionnaire pour stocker les maîtrises de champions pour chaque invocateur par PUUID\n",
    "    mastery_dict = {}\n",
    "\n",
    "    # Remplir le dictionnaire avec les maîtrises de champions\n",
    "    for puuid in summid_to_puuid.values():\n",
    "        time.sleep(1.3)\n",
    "        # Faire une requête pour les maîtrises de champions, stocker dans une variable\n",
    "        response = requests.get(f'https://{region}.api.riotgames.com/lol/champion-mastery/v4/champion-masteries/by-puuid/{puuid}?api_key={api_key}')\n",
    "        \n",
    "        masteries = response.json()\n",
    "        # Convertir la réponse en DataFrame pour filtrer les champions avec des points de maîtrise élevés\n",
    "        df = pd.DataFrame(masteries)\n",
    "\n",
    "        # Ajouter les champions ayant plus de 'points' de maîtrise au dictionnaire\n",
    "        high_mastery_champs = df.query(f'championPoints > {points}')['championId'].tolist()\n",
    "        mastery_dict[puuid] = high_mastery_champs\n",
    "\n",
    "    return mastery_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list_from_json(filename: str) -> list:\n",
    "    \"\"\"\n",
    "    Charge une liste à partir d'un fichier JSON.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Le nom du fichier JSON.\n",
    "\n",
    "    Returns:\n",
    "        list: La liste chargée.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        my_list = json.load(file)\n",
    "    return my_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ids_json = load_list_from_json('get_top_players.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puuid_json = load_list_from_json('get_puuid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_n_items(my_dict: dict, n: int) -> dict:\n",
    "    \"\"\"\n",
    "    Extrait les n premières clés et valeurs d'un dictionnaire.\n",
    "\n",
    "    Args:\n",
    "        my_dict (dict): Le dictionnaire d'origine.\n",
    "        n (int): Le nombre d'éléments à extraire.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire contenant les n premiers éléments.\n",
    "    \"\"\"\n",
    "    return {key: my_dict[key] for key in list(my_dict.keys())[:n]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puuid_json_10 = get_first_n_items(puuid_json,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valeur du 1er élément\n",
    "puuid_json[next(iter(puuid_json))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'euw1'\n",
    "\n",
    "\n",
    "# summoner_ids = get_top_players(region=region)\n",
    "# logging.info(f\"Top players stored: {len(summoner_ids)} entries.\")\n",
    "\n",
    "\n",
    "# summid_to_puuid = get_puuid(summoner_ids=summoner_ids)\n",
    "# logging.info(\"puuids retrieved.\")\n",
    "\n",
    "# mastery_dict = get_champ_mastery(summoner_ids=sum_ids_json, summid_to_puuid=puuid_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_champ_mastery a pris 388 m 36.5 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_list_to_json(mastery_dict, 'mastery_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mastery_dict = load_list_from_json('mastery_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data(mastery_dict, num_matches=10, region ='europe'):\n",
    "    '''\n",
    "    takes in mastery_dict and returns a list of dicts of match data,\n",
    "    as well as a set of all match IDs scanned\n",
    "    num_matches: between 1-100\n",
    "    '''\n",
    "\n",
    "    #create list to store dict objects\n",
    "    data_rows = []\n",
    "\n",
    "    #store set of matches already looked through\n",
    "    matches_scanned = set()\n",
    "\n",
    "    #list of features we want to record\n",
    "    features = ['puuid', 'championId', 'item0', 'item1', 'item2', 'item3', 'item4',\n",
    "                'item5', 'item6', 'kills', 'deaths', 'assists', 'totalDamageDealtToChampions',\n",
    "                'role', 'teamPosition', 'teamId', 'gameEndedInEarlySurrender', 'win',\n",
    "                'longestTimeSpentLiving', 'neutralMinionsKilled', 'needVisionPings',\n",
    "                'sightWardsBoughtInGame', 'timeCCingOthers', 'totalDamageShieldedOnTeammates',\n",
    "                'totalAllyJungleMinionsKilled', 'totalEnemyJungleMinionsKilled', 'totalHealsOnTeammates',\n",
    "                'totalMinionsKilled', 'turretKills', 'turretTakedowns', 'visionScore', 'visionClearedPings',\n",
    "                'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced']\n",
    "                \n",
    "    features_challenges = ['controlWardsPlaced', 'damageTakenOnTeamPercentage', 'dodgeSkillShotsSmallWindow', 'firstTurretKilled',\n",
    "                           'earlyLaningPhaseGoldExpAdvantage', 'laningPhaseGoldExpAdvantage', 'junglerKillsEarlyJungle',\n",
    "                           'maxCsAdvantageOnLaneOpponent', 'maxLevelLeadLaneOpponent', 'killsOnLanersEarlyJungleAsJungler',\n",
    "                           'acesBefore15Minutes', 'killParticipation', 'laneMinionsFirst10Minutes', 'pickKillWithAlly',\n",
    "                           'quickFirstTurret', 'quickSolokills', 'skillshotsDodged', 'skillshotsHit', 'takedownsAfterGainingLevelAdvantage',\n",
    "                           'teamDamagePercentage', 'turretPlatesTaken', 'kTurretsDestroyedBeforePlatesFall', 'wardTakedowns',\n",
    "                           'wardTakedownsBefore20M', 'wardsGuarded'\n",
    "                ]\n",
    "\n",
    "    #expecting API errors\n",
    "    for key, value in mastery_dict.items():\n",
    "\n",
    "        #store matchlist for each puuid\n",
    "        # try:\n",
    "            # match_list = lol_watcher.match.matchlist_by_puuid(region, key, count = num_matches)\n",
    "        response = requests.get(f'https://{region}.api.riotgames.com/lol/match/v5/matches/by-puuid/{key}/ids?start=0&count={num_matches}&api_key={api_key}')\n",
    "        match_list = response.json()\n",
    "        # except ApiError as e:\n",
    "        #     if e.response.status_code == 429:\n",
    "        print(f'match_list : {match_list}')\n",
    "        if isinstance(match_list, dict):\n",
    "            # Si c'est un dictionnaire, vérifiez le code de statut\n",
    "            if 'status' in match_list and match_list['status'].get('status_code') == 429:\n",
    "                print(f\"Rate limit exceeded: {match_list['status']['status_code']}. Waiting 120s\")\n",
    "                time.sleep(120)\n",
    "            #     print(\"bad or expired API key, paste new one here:\")\n",
    "            #     api_key = input()\n",
    "            #     update_key(api_key=api_key)\n",
    "            #     match_list = lol_obj.lol_watcher.match.matchlist_by_puuid(region, key, count = num_matches)\n",
    "            # else:\n",
    "                # print(f\"{match_list['status']['status_code']}: Waiting 10s\")\n",
    "                # time.sleep(10)\n",
    "                response = requests.get(f'https://{region}.api.riotgames.com/lol/match/v5/matches/by-puuid/{key}/ids?start=0&count={num_matches}&api_key={api_key}')\n",
    "                match_list = response.json()\n",
    "\n",
    "        # except ConnectionError as e:\n",
    "        #     print(f\"Connection Error, waiting 10s then resuming\")\n",
    "        #     time.sleep(10)\n",
    "        #     response = requests.get(f'https://{region}.api.riotgames.com/lol/match/v5/matches/by-puuid/{key}/ids?start=0&count={num_matches}&api_key={api_key}')\n",
    "        #     match_list = response.json()\n",
    "        # print(f'match_list : {match_list}')\n",
    "        \n",
    "        for match in match_list:\n",
    "            if match not in matches_scanned:\n",
    "\n",
    "                #store match data in variable\n",
    "                # try:\n",
    "                # match_data = lol_watcher.match.by_id(region, match)\n",
    "                response = requests.get(f'https://{region}.api.riotgames.com/lol/match/v5/matches/{match}?api_key={api_key}')\n",
    "                match_data = response.json()\n",
    "                \n",
    "                print(f'match_data : {match_data}')\n",
    "                \n",
    "                if isinstance(match_data, dict):\n",
    "                    # Si c'est un dictionnaire, vérifiez le code de statut\n",
    "                    if 'status' in match_data and match_data['status'].get('status_code') == 429:\n",
    "                        print(f\"Rate limit exceeded: {match_data['status']['status_code']}. Waiting 120s\")\n",
    "                        time.sleep(120)\n",
    "                    #     print(\"bad or expired API key, paste new one here:\")\n",
    "                    #     api_key = input()\n",
    "                    #     update_key(api_key=api_key)\n",
    "                    #     match_data = lol_watcher.match.by_id(region, match)\n",
    "                    # else:\n",
    "                        # print(\"Connection error, waiting 10s then resuming operation\")\n",
    "                        # time.sleep(10)\n",
    "                        response = requests.get(f'https://{region}.api.riotgames.com/lol/match/v5/matches/{match}?api_key={api_key}')\n",
    "                        match_data = response.json()\n",
    "\n",
    "                # except ConnectionError as e:\n",
    "                #     print(f\"Connection Error, waiting 10s then resuming\")\n",
    "                #     time.sleep(10)\n",
    "                #     # match_data = lol_watcher.match.by_id(region, match)\n",
    "                #     response = requests.get(f'https://{region}.api.riotgames.com/lol/match/v5/matches/{match}?api_key={api_key}')\n",
    "                #     match_data = response.json()\n",
    "                \n",
    "                #store participant information in variable to iterate over (list of dicts) if classic game\n",
    "                \n",
    "                if match_data['info']['gameMode'] == 'CLASSIC':\n",
    "                    player_info = match_data['info']['participants']\n",
    "                    #create dict of champs on team1, team2\n",
    "                    champions_in_game = {}\n",
    "                    champions_in_game[100] = []\n",
    "                    champions_in_game[200] = []\n",
    "                ### CODE DE BASE QUI NOUS INTERESSE ###\n",
    "                    # for player in player_info:\n",
    "                    #     #add champ played to dict\n",
    "                    #     champions_in_game[player['teamId']].append(player['championId'])\n",
    "                    #     #check to see if player in our list of masters+ players\n",
    "                    #     if player['puuid'] in mastery_dict.keys():\n",
    "                    #         #check to see if player on a high mastery champ\n",
    "                    #         if player['championId'] in mastery_dict[player['puuid']]:\n",
    "                    #             #get player data, store in dictionary\n",
    "                    #             player_data = {}\n",
    "                    #             for feature in features:\n",
    "                    #                 player_data[feature] = player[feature]\n",
    "                    #             player_data['patch'] = match_data['info']['gameVersion']\n",
    "                    #             player_data['match_id'] = match\n",
    "                    #             player_data['champions_in_game'] = champions_in_game\n",
    "                                \n",
    "                    #             #append dictionary to list\n",
    "                    #             data_rows.append(player_data)\n",
    "                ### FIN DU CODE QUI NOUS INTERESSE ###\n",
    "                \n",
    "                # Parcours des joueurs dans player_info\n",
    "                    for idx, player in enumerate(player_info):  # Ajout de 'enumerate' pour obtenir l'index du joueur\n",
    "                        # Ajouter le champion joué au dictionnaire 'champions_in_game'\n",
    "                        champions_in_game[player['teamId']].append(player['championId'])\n",
    "                        # Vérifier si le joueur est dans la liste des joueurs avec maîtrise\n",
    "                        # print(player['puuid'] in mastery_dict.keys())\n",
    "                        if player['puuid'] in mastery_dict.keys():\n",
    "                            # Vérifier si le joueur utilise un champion avec une haute maîtrise\n",
    "                            if player['championId'] in mastery_dict[player['puuid']]:\n",
    "                                # Obtenir les données du joueur, stocker dans un dictionnaire\n",
    "                                player_data = {}\n",
    "                                # Ajouter les variables principales du joueur à 'player_data'\n",
    "                                for feature in features:\n",
    "                                    player_data[feature] = player[feature]\n",
    "                                # Ajouter des informations supplémentaires\n",
    "                                player_data['patch'] = match_data['info']['gameVersion']\n",
    "                                player_data['match_id'] = match\n",
    "                                player_data['champions_in_game'] = champions_in_game\n",
    "                                # Ajouter les variables issues de 'challenges' avec suffixe pour chaque participant\n",
    "                                for challenge in features_challenges:\n",
    "                                    player_data[challenge] = player['challenges'].get(challenge, None)  # Utilisation de .get() pour éviter les KeyError si la variable n'existe pas\n",
    "\n",
    "                                # Ajouter le dictionnaire 'player_data' à la liste 'data_rows'\n",
    "                                data_rows.append(player_data)\n",
    "                \n",
    "                \n",
    "                    # for challenge in player_challenges:\n",
    "                        \n",
    "                    #print out to watch progress\n",
    "                    #print('champion ID: ',player_data['championId'],', win:',player_data['win'])\n",
    "                    #print('champs in game: ',player_data['champions_in_game'])\n",
    "\n",
    "                #append match_id to matches_scanned set\n",
    "                matches_scanned.add(match)\n",
    "\n",
    "    return data_rows, matches_scanned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = list(mastery_dict.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get(f'https://europe.api.riotgames.com/lol/match/v5/matches/by-puuid/{key}/ids?start=0&count={10}&api_key={api_key}')\n",
    "# match = response.json()\n",
    "# print(match)\n",
    "# response = requests.get(f'https://europe.api.riotgames.com/lol/match/v5/matches/{match[0]}?api_key={api_key}')\n",
    "# match_data = response.json()\n",
    "# match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('match_data_test.json', 'w') as fichier_json:\n",
    "#     json.dump(match_data, fichier_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('match_data_test.json', 'r') as fichier_json:\n",
    "    match_data = json.load(fichier_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_data['info']['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_challenges = ['controlWardsPlaced', 'damageTakenOnTeamPercentage', 'dodgeSkillShotsSmallWindow', 'firstTurretKilled',\n",
    "                           'earlyLaningPhaseGoldExpAdvantage', 'laningPhaseGoldExpAdvantage', 'junglerKillsEarlyJungle',\n",
    "                           'maxCsAdvantageOnLaneOpponent', 'maxLevelLeadLaneOpponent', 'killsOnLanersEarlyJungleAsJungler',\n",
    "                           'acesBefore15Minutes', 'killParticipation', 'laneMinionsFirst10Minutes', 'pickKillWithAlly',\n",
    "                           'quickFirstTurret', 'quickSolokills', 'skillshotsDodged', 'skillshotsHit', 'takedownsAfterGainingLevelAdvantage',\n",
    "                           'teamDamagePercentage', 'turretPlatesTaken', 'kTurretsDestroyedBeforePlatesFall', 'wardTakedowns',\n",
    "                           'wardTakedownsBefore20M', 'wardsGuarded', \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info = match_data['info']['participants']\n",
    "player_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in player_info:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(player_info):\n",
    "    print(i)\n",
    "    print(j['puuid'] in mastery_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mastery_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mastery_dict_10 = get_first_n_items(mastery_dict,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = get_match_data(mastery_dict=mastery_dict_10, num_matches=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rows, matches_scanned = get_match_data(mastery_dict=get_first_n_items(mastery_dict,1000), num_matches=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(matches_scanned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_list_to_json(data_rows, 'data_rows.json')\n",
    "# with open('matches_scanned.json', 'w') as fichier_json:\n",
    "#     json.dump(list(matches_scanned), fichier_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows = load_list_from_json('data_rows.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_scanned = load_list_from_json('matches_scanned.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_df(data_rows):\n",
    "    '''\n",
    "    converts data_rows (list of dicts) into dataframe, and manipulates columns to be sql-supported datatypes.\n",
    "    '''\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data_rows)\n",
    "    #drop where teamPosition empty\n",
    "    df = df[df['teamPosition'] != '']\n",
    "    #drop where game ended in early surrender\n",
    "    df = df[df['gameEndedInEarlySurrender'] == False]\n",
    "\n",
    "    #lets construct columns from the teamId and champions_in_game column\n",
    "\n",
    "    #new column, list of champions on player's team\n",
    "    df['teammates_championId'] = df.apply(lambda x: x['champions_in_game'].get(x['teamId']), axis=1)\n",
    "\n",
    "    #new column, list of enemy champions\n",
    "    opposite_team_dict = {100:200, 200:100}\n",
    "    df['opposite_team_id'] = df['teamId'].map(opposite_team_dict)\n",
    "    df['enemies_championId'] = df.apply(lambda x: x['champions_in_game'].get(x['opposite_team_id']), axis=1)\n",
    "\n",
    "    #split list into individual columns\n",
    "    player_cols = [\"enemies_championId\", \"teammates_championId\"]\n",
    "    for col in player_cols:\n",
    "        temp_df = df[col].apply(pd.Series)\n",
    "        temp_df = temp_df.add_prefix(col[:-10])\n",
    "        df = pd.concat([df, temp_df], axis=1)\n",
    "\n",
    "    #drop redundant columns\n",
    "    df = df.drop(labels=[\"teammates_championId\", \"enemies_championId\"], axis=1)\n",
    "    df = df.drop(labels=[\"champions_in_game\",\"opposite_team_id\"], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match = match_to_df(data_rows=data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_json(url, file_path):\n",
    "    response = requests.get(url)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded and saved new JSON file at {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datadragon_version(local_file_path):\n",
    "    # Set URL and local JSON file paths\n",
    "    url = \"https://ddragon.leagueoflegends.com/api/versions.json\"\n",
    "    local_file_path = \"data/version.json\"\n",
    "\n",
    "    # Download JSON if local file doesn't exist\n",
    "    if not os.path.exists(local_file_path):\n",
    "        download_json(url, local_file_path)\n",
    "    else:\n",
    "        # Load local and remote JSON files\n",
    "        with open(local_file_path, 'r') as local_file:\n",
    "            local_data = json.load(local_file)\n",
    "\n",
    "        remote_data = requests.get(url).json()\n",
    "\n",
    "        # Compare local and remote JSON files\n",
    "        if local_data != remote_data:\n",
    "            download_json(url, local_file_path)\n",
    "        else:\n",
    "            print(\"Local JSON file is already up-to-date.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file_path = \"data/version.json\"\n",
    "get_datadragon_version(local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tarball(url, file_path):\n",
    "    response = requests.get(url)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "def extract_tarball(file_path, version):\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=f\"data/{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datadragon(local_file_path):\n",
    "    #get version\n",
    "    with open(local_file_path, 'r') as local_file:\n",
    "        data = json.load(local_file)\n",
    "    version = data[0]\n",
    "    \n",
    "    #check to see if latest already downloaded\n",
    "    if os.path.exists(f\"data/{version}\"):\n",
    "        print(f\"Latest Data Dragon folder present. If you believe this is an error, delete the folder at data/{version} in this project directory and re-run this script.\")\n",
    "        return 0\n",
    "\n",
    "    #set url, tar path\n",
    "    url = f\"https://ddragon.leagueoflegends.com/cdn/dragontail-{version}.tgz\"\n",
    "    tar_path = f\"data/{version}.tgz\"\n",
    "\n",
    "    #download tarball\n",
    "    print(f\"Downloading datadragon version {version}\")\n",
    "    download_tarball(url=url, file_path=tar_path)\n",
    "\n",
    "    print(f\"Unpacking tarball...\")\n",
    "    extract_tarball(file_path=tar_path, version=version)\n",
    "\n",
    "    print(\"Deleting tarball...\")\n",
    "    os.remove(tar_path)\n",
    "    print(\"Great Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_datadragon(local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def df_to_sql(df, database='data/matches.db', table_name='player_items_champions'):\n",
    "#     '''\n",
    "#     stores dataframe into a sql database. appends data to table if table already exists.\n",
    "#     '''\n",
    "#     conn = sqlite3.connect(database)\n",
    "#     df.to_sql(name=\"player_items_champions\", con=conn, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajouter_colonnes_manquantes(df, conn, table_name='player_items_champions'):\n",
    "    \"\"\"\n",
    "    Vérifie s'il manque des colonnes dans la table SQL et les ajoute si nécessaire.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Récupérer les colonnes existantes dans la table SQL\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    colonnes_existantes = [info[1] for info in cursor.fetchall()]\n",
    "    \n",
    "    # Obtenir les colonnes du DataFrame\n",
    "    colonnes_df = df.columns\n",
    "    \n",
    "    # Identifier les colonnes manquantes\n",
    "    colonnes_manquantes = set(colonnes_df) - set(colonnes_existantes)\n",
    "    \n",
    "    # Ajouter les colonnes manquantes dans la table SQL\n",
    "    for colonne in colonnes_manquantes:\n",
    "        # Ici, je suppose que toutes les colonnes manquantes sont de type TEXT. Tu peux ajuster les types en fonction de tes besoins.\n",
    "        ajouter_colonne_sql = f\"ALTER TABLE {table_name} ADD COLUMN {colonne} TEXT;\"\n",
    "        cursor.execute(ajouter_colonne_sql)\n",
    "        print(f\"Colonne manquante ajoutée : {colonne}\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation avec la fonction pour stocker les données dans la base\n",
    "def df_to_sql(df, database='data/matches.db', table_name='player_items_champions'):\n",
    "    \"\"\"\n",
    "    Stocke le dataframe dans une base de données SQL. Ajoute des colonnes si elles n'existent pas.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(database)\n",
    "    \n",
    "    # Ajouter les colonnes manquantes si nécessaire\n",
    "    ajouter_colonnes_manquantes(df, conn, table_name)\n",
    "    \n",
    "    # Ensuite, insérer les données dans la table\n",
    "    df.to_sql(name=table_name, con=conn, if_exists='append', index=False)\n",
    "    \n",
    "    print(\"Données stockées dans la base SQL\")\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_sql(df=df_match)\n",
    "logging.info(\"Stored in sql database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ouvrir_table_sql(database='data/matches.db', table_name='player_items_champions'):\n",
    "    # Connexion à la base de données\n",
    "    conn = sqlite3.connect(database)\n",
    "    \n",
    "    # Lire la table SQL dans un DataFrame pandas\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n",
    "    \n",
    "    # Fermer la connexion\n",
    "    conn.close()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_csv = pd.DataFrame(columns= ['id'])\n",
    "# create_csv.to_csv('data/champ_matrix_filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(db='data/matches.db',table=\"player_items_champions\"):\n",
    "    \"\"\"Load data from database and return as pandas dataframe\"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "    conn.close()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_champ_df(version_filepath='data/version.json', feature_filepath='data/champ_matrix_filled.csv', save=True):\n",
    "    \"\"\"Create dataframe of champions and their attributes\"\"\"\n",
    "\n",
    "    # open json file, get version\n",
    "    f = open(version_filepath)\n",
    "    version = json.load(f)[0]\n",
    "\n",
    "    # open json file, get data\n",
    "    f = open(f'data/{version}/{version}/data/fr_FR/champion.json', encoding=\"utf8\")\n",
    "    champ_data = json.load(f)['data']\n",
    "\n",
    "    # define features we want to keep\n",
    "    features = ['version','id','key','name', 'info', 'tags']\n",
    "\n",
    "    #create a list of dictionaries, each dictionary is a champion\n",
    "    champ_list = []\n",
    "    for key, value in champ_data.items():\n",
    "        champ_dict = {}\n",
    "        temp = value\n",
    "        for feature in features:\n",
    "            champ_dict[feature] = temp[feature]\n",
    "            if feature == 'info':\n",
    "                for key, value in value[feature].items():\n",
    "                    champ_dict[key] = value\n",
    "        champ_list.append(champ_dict)\n",
    "\n",
    "    # create dataframe from list of dictionaries\n",
    "    champ_df = pd.DataFrame().from_dict(champ_list)\n",
    "    champ_df = champ_df.drop(labels=['info'], axis=1)\n",
    "\n",
    "    #load in manually-defined feature csv and join with current dataframe\n",
    "    champ_features = ['version','id','mobility','poke','sustained','burst','engage','disengage','healing']\n",
    "    try:\n",
    "        temp_df = pd.read_csv('data/champ_matrix_filled.csv')\n",
    "    except:\n",
    "        print(\"Self-annotated data not found at data/champ_matrix_filled.csv. Create this file using the instructions from the github repository, or download it.\")\n",
    "        raise\n",
    "\n",
    "    #return any champions present in local datadragon files but not in our manually-created feature matrix\n",
    "    new_champs = list(set(champ_df['id']).difference(set(temp_df['id'])))\n",
    "    changelist = {}\n",
    "    for champ in new_champs:\n",
    "        champ_entry = pd.DataFrame({\"id\": [champ], \"version\": [version]})\n",
    "        print(champ_entry)\n",
    "        temp_df = pd.concat([temp_df, champ_entry], ignore_index=True)\n",
    "\n",
    "        print(f\"New champion {champ} needs features added! For each prompt, provide a value from 0-3 for the character, then press enter.\\n\")\n",
    "        champ_attr = {}\n",
    "        for f in champ_features[2:]:\n",
    "            print(f\"{f}: \")\n",
    "            champ_attr[f] = int(input()) #TODO: Add input validation\n",
    "            temp_df.loc[temp_df['id'] == champ, f] = champ_attr[f]\n",
    "\n",
    "        changelist[champ] = champ_attr\n",
    "\n",
    "        if save:\n",
    "            temp_df.to_csv('data/champ_matrix_filled.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    temp_df = temp_df[champ_features]\n",
    "\n",
    "    champ_df = champ_df.merge(temp_df, how=\"left\", on=\"id\")\n",
    "    champ_df[\"version\"] = champ_df[\"version_x\"]\n",
    "    champ_df = champ_df.drop(labels=[\"version_x\", \"version_y\"], axis=1)\n",
    "\n",
    "    #add new champ features\n",
    "    for champ, attr in changelist.items():\n",
    "        for key, value in attr.items():\n",
    "            champ_df.loc[champ_df['id'] == champ, key] = value\n",
    "        print(f\"Updated entry for {champ}!\")\n",
    "\n",
    "    #one hot encode the tags column, and sum to get back to original row shape\n",
    "    temp_df = pd.get_dummies(champ_df['tags'].explode(), columns=['tags'])\n",
    "    temp_df = temp_df.groupby(temp_df.index).sum()\n",
    "\n",
    "    #merge temp_df with champ_df\n",
    "    champ_df = pd.concat([champ_df, temp_df],axis=1)\n",
    "\n",
    "    #transform key column to int\n",
    "    champ_df['key'] = champ_df['key'].astype(int)\n",
    "\n",
    "    #drop tags and difficulty columns\n",
    "    champ_df = champ_df.drop(labels=['tags','difficulty'], axis=1)\n",
    "\n",
    "    #move version column back to front\n",
    "    cols = champ_df.columns.tolist()\n",
    "    cols.remove('version')\n",
    "    cols.insert(0, 'version')\n",
    "    champ_df = champ_df[cols]\n",
    "\n",
    "    if save:\n",
    "        champ_df.to_csv('data/champ_df.csv', index=False)\n",
    "\n",
    "    return champ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summed_features(df, champ_df):\n",
    "    \"\"\"Get summed features for ally and enemy teams\"\"\"\n",
    "\n",
    "    #champ_df indices we want\n",
    "    cols = champ_df.columns[4:].to_list()\n",
    "\n",
    "    #create unique for ally and enemy sums\n",
    "    ally_cols = [\"ally_\" + x for x in cols]\n",
    "    enemy_cols = [\"enemy_\" + x for x in cols]\n",
    "\n",
    "    #new dataframe to store vals in\n",
    "    summed_features = pd.DataFrame(columns=ally_cols+enemy_cols)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        #enemies list\n",
    "        enemy_ids = row[21:26].to_list()\n",
    "        #ally list\n",
    "        ally_ids = row[26:31].to_list()\n",
    "\n",
    "        #list of vals to fill\n",
    "        ally_stats = champ_df[champ_df['key'].isin(ally_ids)].sum()[4:].to_list()\n",
    "        enemy_stats = champ_df[champ_df['key'].isin(enemy_ids)].sum()[4:].to_list()\n",
    "\n",
    "        stats = ally_stats + enemy_stats\n",
    "        summed_features.loc[len(summed_features)] = stats\n",
    "\n",
    "    #merge with match_ids\n",
    "    df = pd.concat([df, summed_features], axis=1)\n",
    "\n",
    "    #create KDA column\n",
    "    df['kda'] = (df['kills'] + df['assists']) / df['deaths']\n",
    "    df.loc[df['deaths'] == 0, 'kda'] = df['kills'] + df['assists'] #where deaths = 0, set kd_ratio to kills + assists\n",
    "\n",
    "    #move the kda column to the front\n",
    "    column_to_move = df.pop(\"kda\") #remove column\n",
    "    #insert column at position 10\n",
    "    df.insert(10, \"kda\", column_to_move)\n",
    "\n",
    "    #return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_db(df, db='data/matches.db', name=\"match_features\"):\n",
    "    conn = sqlite3.connect(db)\n",
    "    df.to_sql(name, conn, if_exists=\"append\", index=False)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.info(\"Loading data...\")\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Creating features...\")\n",
    "champ_df = create_champ_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summed_features(df, champ_df):\n",
    "    \"\"\"Get summed features for ally and enemy teams\"\"\"\n",
    "\n",
    "    #champ_df indices we want\n",
    "    cols = champ_df.columns[4:].to_list()\n",
    "\n",
    "    #create unique for ally and enemy sums\n",
    "    ally_cols = [\"ally_\" + x for x in cols]\n",
    "    enemy_cols = [\"enemy_\" + x for x in cols]\n",
    "\n",
    "    #new dataframe to store vals in\n",
    "    summed_features = pd.DataFrame(columns=ally_cols+enemy_cols)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        #enemies list\n",
    "        enemy_ids = row[21:26].to_list()\n",
    "        #ally list\n",
    "        ally_ids = row[26:31].to_list()\n",
    "\n",
    "        #list of vals to fill\n",
    "        ally_stats = champ_df[champ_df['key'].isin(ally_ids)].sum()[4:].to_list()\n",
    "        enemy_stats = champ_df[champ_df['key'].isin(enemy_ids)].sum()[4:].to_list()\n",
    "\n",
    "        stats = ally_stats + enemy_stats\n",
    "        summed_features.loc[len(summed_features)] = stats\n",
    "\n",
    "    #merge with match_ids\n",
    "    df = pd.concat([df, summed_features], axis=1)\n",
    "\n",
    "    #create KDA column\n",
    "    df['kda'] = (df['kills'] + df['assists']) / df['deaths']\n",
    "    df.loc[df['deaths'] == 0, 'kda'] = df['kills'] + df['assists'] #where deaths = 0, set kd_ratio to kills + assists\n",
    "\n",
    "    #move the kda column to the front\n",
    "    column_to_move = df.pop(\"kda\") #remove column\n",
    "    #insert column at position 10\n",
    "    df.insert(10, \"kda\", column_to_move)\n",
    "\n",
    "    #return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_summed_features(df, champ_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.info(\"Saving to database...\")\n",
    "# save_to_db(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(table=\"match_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df):\n",
    "    \"\"\"Normalize the dataframe, keep min and max stored for normalizing new entries\"\"\"\n",
    "    #normalize our columns\n",
    "    df_scaled = df.copy()\n",
    "    #store max, min in dict\n",
    "    norm_dict = {}\n",
    "    for column in df.columns[31:]:\n",
    "        print(f\"column : {column}\")\n",
    "        norm_dict[column] = [df_scaled[column].max(), df_scaled[column].min()]\n",
    "        df_scaled[column] = (df_scaled[column] - df_scaled[column].min()) / (df_scaled[column].max() - df_scaled[column].min())\n",
    "\n",
    "    return df_scaled, norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[31:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wardTakedowns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Normalizing dataframe...')\n",
    "df_scaled, norm_dict = normalize_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pwd\n",
    "import platform\n",
    "import argparse\n",
    "import requests\n",
    "from scipy.spatial import KDTree\n",
    "from feature_build import load_data\n",
    "\n",
    "# Disable SSL warnings\n",
    "requests.packages.urllib3.disable_warnings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list to store dict objects\n",
    "data_rows = []\n",
    "            \n",
    "#store set of matches already looked through\n",
    "matches_scanned = set()\n",
    "\n",
    "#list of features we want to record\n",
    "features = ['puuid', 'championId', 'item0', 'item1', 'item2', 'item3', 'item4', 'item5', 'item6', \n",
    "            'kills', 'deaths', 'assists', 'totalDamageDealtToChampions', 'role', 'teamPosition', 'teamId', 'gameEndedInEarlySurrender', 'win']\n",
    "\n",
    "retries = 0\n",
    "max_retries = 10\n",
    "region = 'euw1'\n",
    "num_matches = 1\n",
    "mastery_dict = C\n",
    "\n",
    "#expecting API errors\n",
    "# while retries < max_retries:\n",
    "    # for key, value in mastery_dict.items():\n",
    "for key in mastery_dict['puuid']:\n",
    "    #store matchlist for each puuid\n",
    "    match_list = lol_watcher.match.matchlist_by_puuid(region, key, count = num_matches)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for match in match_list:\n",
    "            if match not in matches_scanned:\n",
    "                #store match data in variable\n",
    "                match_data = lol_watcher.match.by_id(region, match)\n",
    "                #store participant information in variable to iterate over (list of dicts) if classic game\n",
    "                if match_data['info']['gameMode'] == 'CLASSIC':\n",
    "                    player_info = match_data['info']['participants']\n",
    "                    #create dict of champs on team1, team2\n",
    "                    champions_in_game = {}\n",
    "                    champions_in_game[100] = []\n",
    "                    champions_in_game[200] = []\n",
    "                    for player in player_info:\n",
    "                        #add champ played to dict\n",
    "                        champions_in_game[player['teamId']].append(player['championId'])\n",
    "                        #check to see if player in our list of masters+ players\n",
    "                        # if player['puuid'] in mastery_dict.keys(): \n",
    "                        if player['puuid'] in list(mastery_dict['puuid']): \n",
    "                            #check to see if player on a high mastery champ\n",
    "                            # if player['championId'] in mastery_dict[player['puuid']]:\n",
    "                            if player['championId'] in list(mastery_dict['championId']):\n",
    "                                #get player data, store in dictionary\n",
    "                                player_data = {}\n",
    "                                for feature in features:\n",
    "                                    player_data[feature] = player[feature]\n",
    "                                player_data['patch'] = match_data['info']['gameVersion']\n",
    "                                player_data['match_id'] = match\n",
    "                                player_data['champions_in_game'] = champions_in_game\n",
    "                                #append dictionary to list\n",
    "                                data_rows.append(player_data)\n",
    "                                \n",
    "                    #print out to watch progress\n",
    "                    #print('champion ID: ',player_data['championId'],', win:',player_data['win'])\n",
    "                    #print('champs in game: ',player_data['champions_in_game'])\n",
    "                                \n",
    "                #append match_id to matches_scanned set\n",
    "                matches_scanned.add(match)\n",
    "                #reset retries\n",
    "                retries = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data(mastery_dict, num_matches=10, region = 'euw1'):\n",
    "    '''\n",
    "    takes in mastery_dict and returns a list of dicts of match data, as well as a set of all match IDs scanned\n",
    "    num_matches: between 1-100\n",
    "    '''\n",
    "\n",
    "    #create list to store dict objects\n",
    "    data_rows = []\n",
    "                \n",
    "    #store set of matches already looked through\n",
    "    matches_scanned = set()\n",
    "\n",
    "    #list of features we want to record\n",
    "    features = ['puuid', 'championId', 'item0', 'item1', 'item2', 'item3', 'item4', 'item5', 'item6', \n",
    "                'kills', 'deaths', 'assists', 'totalDamageDealtToChampions', 'role', 'teamPosition', 'teamId', 'gameEndedInEarlySurrender', 'win']\n",
    "    \n",
    "    retries = 0\n",
    "    max_retries = 10\n",
    "    \n",
    "    #expecting API errors\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # for key, value in mastery_dict.items():\n",
    "            for key in mastery_dict['puuid']:\n",
    "                #store matchlist for each puuid\n",
    "                match_list = lol_watcher.match.matchlist_by_puuid(region, key, count = num_matches)\n",
    "                for match in match_list:\n",
    "                    if match not in matches_scanned:\n",
    "                        #store match data in variable\n",
    "                        match_data = lol_watcher.match.by_id(region, match)\n",
    "                        #store participant information in variable to iterate over (list of dicts) if classic game\n",
    "                        if match_data['info']['gameMode'] == 'CLASSIC':\n",
    "                            player_info = match_data['info']['participants']\n",
    "                            #create dict of champs on team1, team2\n",
    "                            champions_in_game = {}\n",
    "                            champions_in_game[100] = []\n",
    "                            champions_in_game[200] = []\n",
    "                            for player in player_info:\n",
    "                                #add champ played to dict\n",
    "                                champions_in_game[player['teamId']].append(player['championId'])\n",
    "                                #check to see if player in our list of masters+ players\n",
    "                                # if player['puuid'] in mastery_dict.keys(): \n",
    "                                if player['puuid'] in list(mastery_dict['puuid']): \n",
    "                                    #check to see if player on a high mastery champ\n",
    "                                    # if player['championId'] in mastery_dict[player['puuid']]:\n",
    "                                    if player['championId'] in list(mastery_dict['championId']):\n",
    "                                        #get player data, store in dictionary\n",
    "                                        player_data = {}\n",
    "                                        for feature in features:\n",
    "                                            player_data[feature] = player[feature]\n",
    "                                        player_data['patch'] = match_data['info']['gameVersion']\n",
    "                                        player_data['match_id'] = match\n",
    "                                        player_data['champions_in_game'] = champions_in_game\n",
    "                                        #append dictionary to list\n",
    "                                        data_rows.append(player_data)\n",
    "                                        \n",
    "                            #print out to watch progress\n",
    "                            #print('champion ID: ',player_data['championId'],', win:',player_data['win'])\n",
    "                            #print('champs in game: ',player_data['champions_in_game'])\n",
    "                                        \n",
    "                        #append match_id to matches_scanned set\n",
    "                        matches_scanned.add(match)\n",
    "                        #reset retries\n",
    "                        retries = 0\n",
    "        #error handling\n",
    "        except exceptions.Forbidden as e:\n",
    "            logging.error(f\"Error: {e}\")\n",
    "            retries += 1\n",
    "            time.sleep(3)\n",
    "            continue\n",
    "\n",
    "        except exceptions.ServiceUnavailable as e:\n",
    "            logging.error(f\"Error: {e}\")\n",
    "            retries += 1\n",
    "            time.sleep(3)\n",
    "            continue\n",
    "\n",
    "    return data_rows, matches_scanned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows, matches_scanned = get_match_data(mastery_dict=mastery_dict, num_matches=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_df(data_rows):\n",
    "    '''\n",
    "    converts data_rows (list of dicts) into dataframe, and manipulates columns to be sql-supported datatypes.\n",
    "    '''\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data_rows)\n",
    "    #drop where teamPosition empty\n",
    "    df = df[df['teamPosition'] != '']\n",
    "    #drop where game ended in early surrender\n",
    "    df = df[df['gameEndedInEarlySurrender'] == False]\n",
    "\n",
    "    #lets construct columns from the teamId and champions_in_game column\n",
    "\n",
    "    #new column, list of champions on player's team\n",
    "    df['teammates_championId'] = df.apply(lambda x: x['champions_in_game'].get(x['teamId']), axis=1)\n",
    "\n",
    "    #new column, list of enemy champions\n",
    "    opposite_team_dict = {100:200, 200:100}\n",
    "    df['opposite_team_id'] = df['teamId'].map(opposite_team_dict)\n",
    "    df['enemies_championId'] = df.apply(lambda x: x['champions_in_game'].get(x['opposite_team_id']), axis=1)\n",
    "\n",
    "    #split list into individual columns\n",
    "    player_cols = [\"enemies_championId\", \"teammates_championId\"]\n",
    "    for col in player_cols:\n",
    "        temp_df = df[col].apply(pd.Series)\n",
    "        temp_df = temp_df.add_prefix(col[:-10])\n",
    "        df = pd.concat([df, temp_df], axis=1)\n",
    "\n",
    "    #drop redundant columns\n",
    "    df = df.drop(labels=[\"teammates_championId\", \"enemies_championId\"], axis=1)\n",
    "    df = df.drop(labels=[\"champions_in_game\",\"opposite_team_id\"], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_sql(df, database='matches.db', table_name='player_items_champions'):\n",
    "    '''\n",
    "    stores dataframe into a sql database. appends data to table if table already exists.\n",
    "    '''\n",
    "    conn = sqlite3.connect(database)\n",
    "    df.to_sql(name=\"player_items_champions\", con=conn, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
